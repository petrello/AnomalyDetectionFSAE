{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üïë **Preparing Data for 2-TBN: Time-Series Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import useful libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utilities import DataEncoder, DBNDataTransformer, DataVisualizer, DataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define basic folder paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder names\n",
    "DATA_FOLDER_NAME = r\".\\data\"\n",
    "\n",
    "DISCRETIZED_ORIGINAL_DATASETS_IMOLA_FOLDER_NAME = os.path.join(DATA_FOLDER_NAME, \"discretized-datasets-imola\")\n",
    "\n",
    "CUT_DATASETS_IMOLA_FOLDER_NAME      = DISCRETIZED_ORIGINAL_DATASETS_IMOLA_FOLDER_NAME\n",
    "KMEANS_DATASETS_IMOLA_FOLDER_NAME   = os.path.join(DISCRETIZED_ORIGINAL_DATASETS_IMOLA_FOLDER_NAME, \"kmeans\")\n",
    "\n",
    "# AGGREGATED_DATASETS_IMOLA_FOLDER_NAME = os.path.join(DATA_FOLDER_NAME, \"aggregated-datasets-imola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Found 3 datasets in '.\\data\\discretized-datasets-imola'\n",
      "\n",
      "üîç [1/3] Loading dataset: .\\data\\discretized-datasets-imola\\discr-20241128-imola.csv\n",
      "   ‚úî Loaded dataset with shape: (248448, 14)\n",
      "   ‚è≥ Creating time-series representation (Full dataset)...\n",
      "   ‚úî Full dataset transformed, new shape: (248447, 28)\n",
      "   ‚è≥ Extracting & transforming NORMAL data...\n",
      "   ‚úî Normal dataset transformed, new shape: (248447, 26)\n",
      "   ‚è≥ Extracting & transforming ANOMALOUS data...\n",
      "   ‚ö† Warning: No anomalous data found in this dataset!\n",
      "‚úÖ Completed processing .\\data\\discretized-datasets-imola\\discr-20241128-imola.csv\n",
      "\n",
      "\n",
      "üîç [2/3] Loading dataset: .\\data\\discretized-datasets-imola\\discr-20250113-imola.csv\n",
      "   ‚úî Loaded dataset with shape: (497553, 14)\n",
      "   ‚è≥ Creating time-series representation (Full dataset)...\n",
      "   ‚úî Full dataset transformed, new shape: (497552, 28)\n",
      "   ‚è≥ Extracting & transforming NORMAL data...\n",
      "   ‚úî Normal dataset transformed, new shape: (439732, 26)\n",
      "   ‚è≥ Extracting & transforming ANOMALOUS data...\n",
      "   ‚úî Anomalous dataset transformed, new shape: (57819, 26)\n",
      "‚úÖ Completed processing .\\data\\discretized-datasets-imola\\discr-20250113-imola.csv\n",
      "\n",
      "\n",
      "üîç [3/3] Loading dataset: .\\data\\discretized-datasets-imola\\discr-20250114-imola.csv\n",
      "   ‚úî Loaded dataset with shape: (603724, 14)\n",
      "   ‚è≥ Creating time-series representation (Full dataset)...\n",
      "   ‚úî Full dataset transformed, new shape: (603723, 28)\n",
      "   ‚è≥ Extracting & transforming NORMAL data...\n",
      "   ‚úî Normal dataset transformed, new shape: (527839, 26)\n",
      "   ‚è≥ Extracting & transforming ANOMALOUS data...\n",
      "   ‚úî Anomalous dataset transformed, new shape: (75883, 26)\n",
      "‚úÖ Completed processing .\\data\\discretized-datasets-imola\\discr-20250114-imola.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV dataset files from the specified folder\n",
    "cut_datasets_imola = glob.glob(os.path.join(CUT_DATASETS_IMOLA_FOLDER_NAME, \"*.csv\"))\n",
    "print(f\"üìÇ Found {len(cut_datasets_imola)} datasets in '{CUT_DATASETS_IMOLA_FOLDER_NAME}'\")\n",
    "\n",
    "# Lists to store transformed time-series data\n",
    "full_time_series_list = []\n",
    "normal_time_series_list = []\n",
    "anomalous_time_series_list = []\n",
    "\n",
    "# Process each dataset\n",
    "for idx, dataset_path in enumerate(cut_datasets_imola, start=1):\n",
    "    print(f\"\\nüîç [{idx}/{len(cut_datasets_imola)}] Loading dataset: {dataset_path}\")\n",
    "    \n",
    "    # Load dataset\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(f\"   ‚úî Loaded dataset with shape: {df.shape}\")\n",
    "\n",
    "    # Transform full dataset into time-series format\n",
    "    print(\"   ‚è≥ Creating time-series representation (Full dataset)...\")\n",
    "    full_time_series = DBNDataTransformer.create_time_series_dbn_data(df, time_slices=2)\n",
    "    full_time_series_list.append(full_time_series)\n",
    "    print(f\"   ‚úî Full dataset transformed, new shape: {full_time_series.shape}\")\n",
    "\n",
    "    # Extract & transform normal data (InverterFault == 0)\n",
    "    print(\"   ‚è≥ Extracting & transforming NORMAL data...\")\n",
    "    normal_df = df[df['InverterFault'] == 0].drop(columns=['InverterFault'])\n",
    "    normal_time_series = DBNDataTransformer.create_time_series_dbn_data(normal_df)\n",
    "    normal_time_series_list.append(normal_time_series)\n",
    "    print(f\"   ‚úî Normal dataset transformed, new shape: {normal_time_series.shape}\")\n",
    "\n",
    "    # Extract & transform anomalous data (InverterFault == 1)\n",
    "    print(\"   ‚è≥ Extracting & transforming ANOMALOUS data...\")\n",
    "    anomalous_df = df[df['InverterFault'] == 1].drop(columns=['InverterFault'])\n",
    "    anomalous_time_series = DBNDataTransformer.create_time_series_dbn_data(anomalous_df)\n",
    "    anomalous_time_series_list.append(anomalous_time_series)\n",
    "    if anomalous_df.empty:\n",
    "        print(\"   ‚ö† Warning: No anomalous data found in this dataset!\")\n",
    "    else:\n",
    "        anomalous_time_series = DBNDataTransformer.create_time_series_dbn_data(anomalous_df)\n",
    "        anomalous_time_series_list.append(anomalous_time_series)\n",
    "        print(f\"   ‚úî Anomalous dataset transformed, new shape: {anomalous_time_series.shape}\")\n",
    "\n",
    "    print(f\"‚úÖ Completed processing {dataset_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all processed time-series data\n",
    "full_time_series = pd.concat(full_time_series_list, ignore_index=True)\n",
    "normal_time_series = pd.concat(normal_time_series_list, ignore_index=True)\n",
    "anomalous_time_series = pd.concat(anomalous_time_series_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¢ Encoding datasets for DBN processing...\n",
      "   ‚úî Full DBN dataset encoded.\n",
      "   ‚úî Normal DBN dataset encoded.\n",
      "   ‚úî Anomalous DBN dataset encoded.\n",
      "‚úÖ Completed datasets encoding.\n"
     ]
    }
   ],
   "source": [
    "# Encode the datasets for DBN\n",
    "print(\"\\nüî¢ Encoding datasets for DBN processing...\")\n",
    "full_dbn_dataset, full_encoding_mappings = DataEncoder.encode_categorical_columns(full_time_series)\n",
    "print(f\"   ‚úî Full DBN dataset encoded.\")\n",
    "normal_dbn_dataset, normal_encoding_mappings = DataEncoder.encode_categorical_columns(normal_time_series)\n",
    "print(f\"   ‚úî Normal DBN dataset encoded.\")\n",
    "anomalous_dbn_dataset, anomalous_encoding_mappings = DataEncoder.encode_categorical_columns(anomalous_time_series)\n",
    "print(f\"   ‚úî Anomalous DBN dataset encoded.\")\n",
    "\n",
    "print(f\"‚úÖ Completed datasets encoding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset Information:\n",
      "Shape: (1349722, 28)\n",
      "Memory usage: 36.04 MB\n",
      "\n",
      "Sample column names:\n",
      "  ('BatteryVoltage_V', 0)\n",
      "  ('BatteryCurrent_A', 0)\n",
      "  ('BatteryPackTemp_C', 0)\n",
      "  ('InverterFault', 0)\n",
      "  ('InverterSpeed_RearLeft_RPM', 0)\n",
      "\n",
      "Normal Dataset Information:\n",
      "Shape: (1216018, 26)\n",
      "Memory usage: 30.15 MB\n",
      "\n",
      "Sample column names:\n",
      "  ('BatteryVoltage_V', 0)\n",
      "  ('BatteryCurrent_A', 0)\n",
      "  ('BatteryPackTemp_C', 0)\n",
      "  ('InverterSpeed_RearLeft_RPM', 0)\n",
      "  ('Inverter_Iq_Ref_RearLeft_A', 0)\n",
      "\n",
      "Anomalous Dataset Information:\n",
      "Shape: (267404, 26)\n",
      "Memory usage: 6.63 MB\n",
      "\n",
      "Sample column names:\n",
      "  ('BatteryVoltage_V', 0)\n",
      "  ('BatteryCurrent_A', 0)\n",
      "  ('BatteryPackTemp_C', 0)\n",
      "  ('InverterSpeed_RearLeft_RPM', 0)\n",
      "  ('Inverter_Iq_Ref_RearLeft_A', 0)\n",
      "\n",
      "Time slices included: [0, 1]\n",
      "\n",
      "NaN values in full dataset: 0\n",
      "NaN values in normal dataset: 0\n",
      "NaN values in anomalous dataset: 0\n",
      "\n",
      "Sample of encoding mappings:\n",
      "  ('BatteryVoltage_V', 0): {'type': 'ordinal', 'categories': ['0_Low', '1_Medium', '2_High'], 'mapping': {'0_Low': 0, '1_Medium': 1, '2_High': 2}}\n",
      "  ('BatteryCurrent_A', 0): {'type': 'ordinal', 'categories': ['0_Idle', '1_Normal', '2_High'], 'mapping': {'0_Idle': 0, '1_Normal': 1, '2_High': 2}}\n",
      "  ('BatteryPackTemp_C', 0): {'type': 'ordinal', 'categories': ['0_Low', '1_Normal', '2_High'], 'mapping': {'0_Low': 0, '1_Normal': 1, '2_High': 2}}\n"
     ]
    }
   ],
   "source": [
    "# Merge encoding mappings\n",
    "encoding_mappings = {**full_encoding_mappings, **normal_encoding_mappings, **anomalous_encoding_mappings}\n",
    "\n",
    "# Display dataset summary\n",
    "DataVisualizer.display_dataset_info(full_dbn_dataset, normal_dbn_dataset, anomalous_dbn_dataset, encoding_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with shape (1349722, 28), saved successfully at .\\data\\dbn-datasets-imola\\full-dbn-imola.csv (csv).\n",
      "Dataset with shape (1216018, 26), saved successfully at .\\data\\dbn-datasets-imola\\normal-dbn-imola.csv (csv).\n",
      "Dataset with shape (267404, 26), saved successfully at .\\data\\dbn-datasets-imola\\anomalous-dbn-imola.csv (csv).\n",
      "‚úÖ Full dataset saved: .\\data\\dbn-datasets-imola\\full-dbn-imola.csv\n",
      "‚úÖ Normal dataset saved: .\\data\\dbn-datasets-imola\\normal-dbn-imola.csv\n",
      "‚úÖ Anomalous dataset saved: .\\data\\dbn-datasets-imola\\anomalous-dbn-imola.csv\n"
     ]
    }
   ],
   "source": [
    "# Define output folder & ensure it exists\n",
    "dbn_output_folder = os.path.join(DATA_FOLDER_NAME, 'dbn-datasets-imola')\n",
    "os.makedirs(dbn_output_folder, exist_ok=True)\n",
    "\n",
    "# Save datasets to CSV files\n",
    "output_files = {\n",
    "    \"full\": os.path.join(dbn_output_folder, \"full-dbn-imola.csv\"),\n",
    "    \"normal\": os.path.join(dbn_output_folder, \"normal-dbn-imola.csv\"),\n",
    "    \"anomalous\": os.path.join(dbn_output_folder, \"anomalous-dbn-imola.csv\"),\n",
    "}\n",
    "\n",
    "DataProcessor.save_dataset(full_dbn_dataset, output_files[\"full\"], file_format=\"csv\")\n",
    "DataProcessor.save_dataset(normal_dbn_dataset, output_files[\"normal\"], file_format=\"csv\")\n",
    "DataProcessor.save_dataset(anomalous_dbn_dataset, output_files[\"anomalous\"], file_format=\"csv\")\n",
    "\n",
    "# Confirm successful saves\n",
    "for key, path in output_files.items():\n",
    "    print(f\"‚úÖ {key.capitalize()} dataset saved: {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
